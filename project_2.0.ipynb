{
  "cells": [
    {
      "metadata": {
        "_uuid": "fa85602858451c431bdddefc1f4a7e5f820f096e",
        "_cell_guid": "f569461f-f4ad-43c9-bda1-f04bd92e8100",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import *\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import StratifiedKFold\nimport random\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "246c2484415f609d524c06ca34a1e41fb6dc490a",
        "_cell_guid": "edac4f2e-3915-4010-8a21-8a83def509de",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint(train.shape)\ntrain.head()\ntest.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa000e5d06afb1b54606e155e3d4663255ac2e0a",
        "_cell_guid": "f92e7d10-033c-4533-88f5-dc902770840e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# found that 'ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin','ps_calc_20_bin' are almost uniform distribution on target = 1\ntrain.drop(['ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin','ps_calc_20_bin'],axis=1,inplace=True)\n# found that 'ps_calc_01','ps_calc_02','ps_calc_03' are uniform distribution on target = 1\ntrain.drop(['ps_calc_01','ps_calc_02','ps_calc_03'],axis=1,inplace=True)\n# found that 'ps_calc_04','ps_calc_09' are uniform distribution on target = 1\ntrain.drop(['ps_calc_04','ps_calc_09'],axis=1,inplace=True)\n# the only sample whose 'ps_car_12' value is -1 and the 'target' value is 0, I think this is a noise sample\ntrain.drop(298018,axis=0,inplace=True) \n\n# 'ps_reg_01','ps_reg_02','ps_reg_03' are correlated and their combination's distribution looks great, like a normal distribution\nps_reg = train['ps_reg_01'].add(train['ps_reg_02']).add(train['ps_reg_03'])\nps_reg.name = 'ps_reg'\ntrain = pd.concat([train,ps_reg],axis=1)\ntrain.drop(['ps_reg_01','ps_reg_02','ps_reg_03'],axis=1,inplace=True)\n#train.drop(['ps_reg_01','ps_reg_02'],axis=1,inplace=True)\n'''\n# 'ps_car_12','ps_car_13' are correlated and their combination's distribution looks great\nps_car = train['ps_car_12'].add(train['ps_car_13'])#.add(train['ps_car_14'])\nps_car.name = 'ps_car_1213'\ntrain = pd.concat([train,ps_car],axis=1)\n#train.drop(['ps_car_12','ps_car_13','ps_car_14'],axis=1,inplace=True)\ntrain.drop(['ps_car_12','ps_car_13'],axis=1,inplace=True)\n'''\ntarget = train['target']\ntrain.drop('target',axis=1,inplace=True)\ntrain.drop('id',axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dc50e43c5e9116d2c061399b00f03ab992dc28dd",
        "scrolled": false,
        "_cell_guid": "6164e180-1548-4fbd-8731-cbbea1304b0f",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\ncat_features = []\nbin_features = []\ncontinue_features = []\nordinal_features = []\nfor i in train.columns[2:]:\n    if i.endswith('_bin'):\n        bin_features.append(i)\n    elif i.endswith('_cat'):\n        cat_features.append(i)\n    elif train[i].dtype == 'float64':\n        continue_features.append(i)\n    elif train[i].dtype == 'int64':\n        ordinal_features.append(i)\nprint ('categorical features:')\nprint (cat_features)\nprint ('binary features:')\nprint (bin_features)\nprint ('continue features:')\nprint (continue_features)\nprint ('ordinal features:')\nprint (ordinal_features)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ed7577243249750da6f131668a9fee6188d65022",
        "_cell_guid": "33e9859b-a6ed-438a-aed4-00f01b78a6d5",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "for feature in cat_features:\n    dummies = pd.get_dummies(train[feature],prefix=feature)[1:]\n    train = pd.concat([train,dummies],axis=1)\n    train.drop(feature,axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e3120550a789cad7b879ba37c878cb5cd4cb4ca",
        "_cell_guid": "592e830c-b968-4d4d-8563-fee3b1d9673f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# found that 'ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin','ps_calc_20_bin' are almost uniform distribution on target = 1\ntest.drop(['ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin','ps_calc_20_bin'],axis=1,inplace=True)\n# found that 'ps_calc_01','ps_calc_02','ps_calc_03' are uniform distribution on target = 1\ntest.drop(['ps_calc_01','ps_calc_02','ps_calc_03'],axis=1,inplace=True)\n# found that 'ps_calc_04','ps_calc_09' are uniform distribution on target = 1\ntest.drop(['ps_calc_04','ps_calc_09'],axis=1,inplace=True)\n# the only sample whose 'ps_car_12' value is -1 and the 'target' value is 0, I think this is a noise sample\ntest.drop(298018,axis=0,inplace=True)\n\n# 'ps_reg_01','ps_reg_02','ps_reg_03' are correlated and their combination's distribution looks great, like a normal distribution\nps_reg = test['ps_reg_01'].add(test['ps_reg_02']).add(test['ps_reg_03'])\nps_reg.name = 'ps_reg'\ntest = pd.concat([test,ps_reg],axis=1)\ntest.drop(['ps_reg_01','ps_reg_02','ps_reg_03'],axis=1,inplace=True)\n#test.drop(['ps_reg_01','ps_reg_02'],axis=1,inplace=True)\n'''\n# 'ps_car_12','ps_car_13' are correlated and their combination's distribution looks great\nps_car = test['ps_car_12'].add(test['ps_car_13'])#.add(test['ps_car_14'])\nps_car.name = 'ps_car_1213'\ntest = pd.concat([test,ps_car],axis=1)\n#test.drop(['ps_car_12','ps_car_13','ps_car_14'],axis=1,inplace=True)\ntest.drop(['ps_car_12','ps_car_13'],axis=1,inplace=True)\n'''\n#target = test['target']\n#test.drop('target',axis=1,inplace=True)\ntest.drop('id',axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c3c531f7587a034abcb0caffd3465d702e64f3e7",
        "scrolled": true,
        "_cell_guid": "a84f4b58-8298-4eae-9463-89105ad0d94a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split(train, target, test_size = 0.25, random_state = 0)\n'''\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ad4fcbcfe508e449f6782edbc71b51c4ee9e1fee",
        "_cell_guid": "69831f0a-c7e0-493c-9fc2-ff6e3ba3982c",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def gini(y, pred):\n    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n    g = 2 * metrics.auc(fpr, tpr) - 1\n    return g\n\ndef gini_normalized(y,pred):\n    return  gini(y, pred) / gini(y, y)\ndef cv_score(model,X,Y,cv=5):\n    kf = StratifiedKFold(n_splits=cv)\n    X = X.as_matrix()\n    Y= Y.as_matrix()\n    score = np.zeros(4)\n    for train_index,test_index in kf.split(X,Y):\n        train_x, test_x = X[train_index],X[test_index]\n        train_y, test_y = Y[train_index],Y[test_index]\n        model.fit(train_x,train_y)\n        pre = model.predict(test_x)\n        pre_proba = model.predict_proba(test_x).T[1]\n        temp = [metrics.accuracy_score(pre,test_y),\n                metrics.fbeta_score(test_y,pre,beta=2.0),\n                metrics.roc_auc_score(test_y,pre_proba),\n                gini_normalized(test_y,pre_proba)]\n        score = np.mean([score,temp],axis=0)\n    return score\ndef saveFigure(x,scores,x_label):\n    scores = np.matrix(scores)\n    fig = plt.figure(figsize = (12,10))\n    length = len(np.ravel(scores[0]))\n    data = pd.DataFrame(data=scores,columns=['acc','F2 score','ROC_AUC','Gini'],index=x)\n    plt.plot(data)\n    plt.xlabel(x_label,fontsize=18)\n    plt.ylabel('CV-scores',fontsize=18)\n    plt.legend(['acc','F2 score','ROC_AUC','Gini'])\n    #plt.show()\n    fig.savefig(x_label+'.png', dpi=fig.dpi)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "81cdd40d98d9769722d9b945645866000ff0e408",
        "_cell_guid": "d69e9246-5c23-47d9-8f67-6e57fd3211c6",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "estimators = np.linspace(50,350,7,dtype=int)\nest_scores = []\nfor est in estimators:\n    clf = xgb.XGBClassifier(n_estimators = est, max_depth = 5, silent = True, n_jobs = -1,\n                        booster='gbtree',random_state=7, subsample = 0.8, colsample_bytree = 0.8,\n                        learning_rate=0.01, objective = 'binary:logistic')#scale_pos_weight\n    est_scores.append(cv_score(clf,x_train,y_train))\nest_scores = np.array(est_scores)\n\nnp.savetxt('xgb_estimators.txt', est_scores, delimiter=',')\nsaveFigure(estimators, est_scores, 'Estimators')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2d7f075c356abe5d4cefc53dc62953e0f8fb10f9",
        "scrolled": true,
        "_cell_guid": "ee802638-f6eb-4cba-bc6d-02f57a492bf1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "np.loadtxt(fname='xgb_iters.txt',delimiter=',')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4d37d9e26ae0fb048cf80daa74e886e2cec93faf",
        "_cell_guid": "ac19bf76-f00f-47b7-8896-10dbe8652dd4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "np.matrix(iter_scores).T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f22661f5250a283f3f79dee18ce4d9007e9403b4",
        "_cell_guid": "a2e21a9e-be1e-4e9f-987f-1b917a764694",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "saveFigure(iterations,iter_scores,'estimators')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "db108bb048ef5710ed3caaaf09c23f10e28a51ca",
        "_cell_guid": "b1b3a79d-0667-483d-8bc5-b4ca8e1d0ce4",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Random Forest"
    },
    {
      "metadata": {
        "_uuid": "9ff489df3922ef49861b452cbd6e842d1db3e1a3",
        "_cell_guid": "216bf0b0-9a12-4046-aac7-eab3271418fd"
      },
      "cell_type": "markdown",
      "source": "# n_estimators (1~300)"
    },
    {
      "metadata": {
        "_uuid": "32678671ee23649345310d6a24678681eeb5e1b6",
        "_cell_guid": "2c64e0a5-65f1-473b-8648-11fefcec9b19",
        "scrolled": true,
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "N_forest = 300\nrf = ensemble.RandomForestClassifier(n_estimators=N_forest, max_depth=5, \n                                     min_samples_leaf=4, n_jobs = -1, oob_score =True, \n                                     max_features='auto', random_state=0, class_weight='balanced_subsample')\nrf.fit(x_train, y_train)\n#features = train.columns.values\nprint(\"----- Training Done -----\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eaa1432f2b9255538c1eb93190b28f052a1bee9d",
        "_cell_guid": "73faa5c4-cf3c-40e2-a870-965fd97b77f4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "votes = rf.estimators_\nvote_results = []\nfor vote in votes:\n    vote_results.append(vote.predict_proba(x_test).T[1])\nmat = np.array(vote_results)\nresult_acc = []\nresult_fb = []\nresult_auc = []\nres = np.mean(mat[:10],axis=0)\nfor i in range(10,N_forest):\n    res = (res + mat[i] ) / 2.0\n    temp = res[:]\n    temp[temp >= 0.5] = 1\n    temp[temp < 0.5] = 0\n    result_acc.append(accuracy_score(y_test,temp))\n    result_fb.append(fbeta_score(y_test,temp,beta=2))\n    result_auc.append(roc_auc_score(y_test,res))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "394f4252da9f823aab90134f2230396eccb0d17b",
        "_cell_guid": "76bb5116-836c-4a1b-8451-7e7222182406",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_acc) # n_estimators=200",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9a209742f49dc351a4a53584672d536f9ad253b9",
        "_cell_guid": "71795ff6-e6da-4a4c-a7a5-e9c908eb6792",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_fb) # n_estimators=200",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c07e896a43e405b83ec45f23e9da62e281960b79",
        "_cell_guid": "a42254f0-bd47-456e-a471-cae1a1b7f9dc",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_auc) # n_estimators=200",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c99f26da8376f4dd0b5088b72987570672ca3fbf",
        "_cell_guid": "f60dd0de-6e67-4335-ae2e-6f205155eb25"
      },
      "cell_type": "markdown",
      "source": "## max_depth = (1~10), min_samples_leaf(1~10)"
    },
    {
      "metadata": {
        "_uuid": "d4f89a0d1872b1b6d0ba8f350c4656be46adc328",
        "_cell_guid": "9e6f9ee4-1eb3-4773-ab0d-b6697a5c9331",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "depths = np.linspace(2,10,9)\nresult_acc = []\nresult_fb = []\nresult_auc = []\nfor depth in depths:\n    rf = ensemble.RandomForestClassifier(n_estimators=100, max_depth=depth, \n                                         min_samples_leaf=4, n_jobs = -1, oob_score =True, \n                                         max_features='auto', random_state=0, class_weight='balanced_subsample')\n    rf.fit(x_train, y_train)\n    temp = rf.predict(x_test)\n    temp_proba = rf.predict_proba(x_test).T[1]\n    result_acc.append(accuracy_score(y_test,temp))\n    result_fb.append(fbeta_score(y_test,temp,beta=2))\n    result_auc.append(roc_auc_score(y_test,temp_proba))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72107f8c6ff92f9abb2e3ffe2066ccdc746f7482",
        "_cell_guid": "0fae6394-c21e-4882-b717-f889ea8957ef",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_acc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "11cee5ef0e6f437de13431b4e935b2c1194d9bc4",
        "_cell_guid": "cf8988d4-ff96-4e0c-b3e3-e7455fdb44c4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_fb)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3fb00776746426bffd23e33d194e276ab37a9c38",
        "_cell_guid": "a93b4fb3-2b90-4d87-88a3-b09f7f59976b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_auc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2de9c13b58f102723f9b742bcb5edefdba9d1e8f",
        "_cell_guid": "ee2be570-8db7-482b-9192-f760db50b129",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "leafs = np.linspace(2,10,9)\nresult_acc = []\nresult_fb = []\nresult_auc = []\nfor leaf in leafs:\n    rf = ensemble.RandomForestClassifier(n_estimators=200, max_depth=5, \n                                         min_samples_leaf = int(leaf), n_jobs = -1, oob_score =True, \n                                         max_features='auto', random_state=0, class_weight='balanced_subsample')\n    rf.fit(x_train, y_train)\n    temp = rf.predict(x_test)\n    temp_proba = rf.predict_proba(x_test).T[1]\n    result_acc.append(accuracy_score(y_test,temp))\n    result_fb.append(fbeta_score(y_test,temp,beta=2))\n    result_auc.append(roc_auc_score(y_test,temp_proba))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fa4bbac679dc0f0aa81b4d1b30d3f0c6d575065d",
        "_cell_guid": "67e0f0b4-4d9c-4ce5-92b4-9a6eb5ed2384",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_acc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c70ddfe02b0429ab745c1953bfccada781ca9362",
        "_cell_guid": "33b3f69f-1838-4c75-aa55-1b67abaef126",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_fb)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ffa31bd13eb4213cc10e3304c4b874cc8a24c352",
        "_cell_guid": "76617bca-b497-4c11-9178-0bd52b2cd000",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(result_auc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "08b83d8ec2489f39d5bee0252cb0bcbe75c66a30",
        "_cell_guid": "3a7041d6-e264-4d68-b0f4-54f1342b73f2",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def gini_rf(pred, y):\n    #y = y.get_label()\n    return 'gini', gini(y, pred) / gini(y, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "03385497d7da7e445169f8d69999eca960ed8c98",
        "_cell_guid": "4ac59436-731e-4416-8ca5-8c4e2fc8f1cb",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# After hyperparameter selection, the good hyperparameters are n_estimators=200, max_depth=5, min_samples_leaf = 4\nrf = ensemble.RandomForestClassifier(n_estimators=200, max_depth=5, \n                                         min_samples_leaf = 4, n_jobs = -1, oob_score =True, \n                                         max_features='auto', random_state=0, class_weight='balanced_subsample')\nrf.fit(x_train, y_train)\ntemp = rf.predict(x_test)\ntemp_proba = rf.predict_proba(x_test).T[1]\n\nprint (gini_rf(temp_proba,y_test))\nprint (\"Random Forest\")\nprint (\"accuracy\",accuracy_score(y_test,temp))\nprint (\"F2 score\", fbeta_score(y_test,temp,beta=2))\nprint (\"ROC_AUC:\",roc_auc_score(y_test, temp_proba))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9ae38cfb5e1b59ee46de1935e70f802c39fc6773",
        "_cell_guid": "91ab9781-bf73-4099-9a64-2cfe3b34f477",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "importance = rf.feature_importances_\nfeatures = train.columns.values\nplt.figure(figsize=(10,12))\nimportance = pd.DataFrame(data=importance,index=features,columns=['importance'])\nimportance.sort_values('importance', ascending=False, inplace=True)\n# Bar plot\n# Order the bars descending on target mean\nsns.barplot(x='importance', y=importance.index, data=importance)\nsns.despine(left=True, bottom=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6cd2dcfb5a756f0ac6627cda5d4569e45eb4d977",
        "_cell_guid": "88303bf3-e98f-4f0f-8170-df5eb3c975ea"
      },
      "cell_type": "markdown",
      "source": "# XGBoost"
    },
    {
      "metadata": {
        "_uuid": "5af913997671134ecba3f2543f472f1a73bba535",
        "_cell_guid": "d3cd5c98-4e8c-4d56-b611-b1e93bebeddf",
        "scrolled": true,
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def gini(y, pred):\n    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n    g = 2 * metrics.auc(fpr, tpr) - 1\n    return g\n\ndef gini_xgb(pred, y):\n    y = y.get_label()\n    return 'gini', gini(y, pred) / gini(y, y)\nrandom.seed( 3 )\nx1, x2, y1, y2 = model_selection.train_test_split(train, target, test_size=0.3, random_state=6)\nwatchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\nparams = {'eta': 0.09, 'max_depth': 6, 'objective': 'binary:logistic', 'seed': 16, 'silent': True, 'colsample_bytree': 0.6}\nmodel = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, feval=gini_xgb, maximize=True, verbose_eval=50, early_stopping_rounds=100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "98354ce1709cdbc77ac98961c8ff76d8a0269844",
        "_cell_guid": "2734874f-f4d3-4be1-a337-d0dc330bb705",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "xgb.plot_importance(model,max_num_features =20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8b891be2746a0b20d0c3bf77e2971ddff174c3ce",
        "_cell_guid": "b9441ec5-6dc9-4be5-bfb8-8534b4429688",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "sns.jointplot(x=\"ps_car_12\", y=\"ps_car_13\", data=train);\nsns.distplot(ps_car);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3be797f8f1f26cf5949c7793edabc0375371520b",
        "_cell_guid": "40880afc-eea2-4060-91a7-303d4eba2251",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "sns.pairplot(train[['ps_reg_01','ps_reg_02','ps_reg_03']]);\nps_reg = train['ps_reg_01'].add(train['ps_reg_02']).add(train['ps_reg_03'])\nsns.distplot(ps_reg);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee69f9c084e0c6dc8746777c2073983d69d4263f",
        "_cell_guid": "73eabac5-9de8-477a-9ae3-ba5f64318b3d"
      },
      "cell_type": "markdown",
      "source": "# LGBM"
    },
    {
      "metadata": {
        "_uuid": "52a5de4901b88878cb16d688b1405ce48cb5afc9",
        "_cell_guid": "6c8890a4-9694-4b3c-9215-995dddf0b1f6",
        "scrolled": true,
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# coding: utf-8\n# pylint: disable = invalid-name, C0111\nimport json\ntry:\n    import cPickle as pickle\nexcept:\n    import pickle\n\n# load or create your dataset\nprint('Load data...')\nnum_train, num_feature = x_train.shape\n\n# create dataset for lightgbm\n# if you want to re-use data, remember to set free_raw_data=False\nlgb_train = lgb.Dataset(x_train, y_train, free_raw_data=False) # weight=W_train,\nlgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train, free_raw_data=False) #weight=W_test,\n\ncolumns = train.columns.values\n\n# specify your configurations as a dict\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc,binary_logloss',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'metric_freq' : 10,\n    'verbose': 0,\n    'is_unbalance': True\n}\n\n# generate a feature name\nfeature_name = ['feature_' + columns[col] for col in range(num_feature)]\n\nprint('Start training...')\n# feature_name and categorical_feature\ngbm = lgb.train(params,\n                lgb_train,\n                #num_boost_round=10,\n                valid_sets=lgb_train,  # eval training data\n                feature_name=feature_name) # ,                categorical_feature=[21]\n\n# check feature name\nprint('Finish first 10 rounds...')\nprint('7th feature name is:', repr(lgb_train.feature_name[6]))\n\n# save model to file\ngbm.save_model('model.txt')\n\n# dump model to json (and save to file)\nprint('Dump model to JSON...')\nmodel_json = gbm.dump_model()\n\nwith open('model.json', 'w+') as f:\n    json.dump(model_json, f, indent=4)\n\n# feature names\nprint('Feature names:', gbm.feature_name())\n\n# feature importances\nprint('Feature importances:', list(gbm.feature_importance()))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dd3bd24fc2f1c642ed6dc1749a814ca801575bec",
        "_cell_guid": "568a06d7-43a2-45af-a5fd-ac37d9004bee",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# load model to predict\nprint('Load model to predict')\nbst = lgb.Booster(model_file='model.txt')\n# can only predict with the best iteration (or the saving iteration)\ny_pred = bst.predict(x_test)\nprint (y_test)\nprint (y_pred)\ntemp = y_pred[:]\ntemp[temp >= 0.5] = 1\ntemp[temp < 0.5] = 0\nprint (\"accuracy\",accuracy_score(y_test,temp))\nprint (\"F2 score\", fbeta_score(y_test,temp,beta=2))\nprint (\"ROC_AUC:\",roc_auc_score(y_test, temp_proba))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f6b2c213ac60b5298a0e0d043c8aeb4f34ac1cd0",
        "_cell_guid": "e0d30840-529a-476f-9a7b-b4a92ccda35e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n# load model to predict\nprint('Load model to predict')\nbst = lgb.Booster(model_file='model.txt')\n# can only predict with the best iteration (or the saving iteration)\ny_pred = bst.predict(X_test)\n# eval with loaded model\nprint('The rmse of loaded model\\'s prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n\n# dump model with pickle\nwith open('model.pkl', 'wb') as fout:\n    pickle.dump(gbm, fout)\n# load model with pickle to predict\nwith open('model.pkl', 'rb') as fin:\n    pkl_bst = pickle.load(fin)\n# can predict with any iteration when loaded in pickle way\ny_pred = pkl_bst.predict(X_test, num_iteration=7)\n# eval with loaded model\nprint('The rmse of pickled model\\'s prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n\n# continue training\n# init_model accepts:\n# 1. model file name\n# 2. Booster()\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=10,\n                init_model='model.txt',\n                valid_sets=lgb_eval)\n\nprint('Finish 10 - 20 rounds with model file...')\n\n# decay learning rates\n# learning_rates accepts:\n# 1. list/tuple with length = num_boost_round\n# 2. function(curr_iter)\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=10,\n                init_model=gbm,\n                learning_rates=lambda iter: 0.05 * (0.99 ** iter),\n                valid_sets=lgb_eval)\n\nprint('Finish 20 - 30 rounds with decay learning rates...')\n\n# change other parameters during training\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=10,\n                init_model=gbm,\n                valid_sets=lgb_eval,\n                callbacks=[lgb.reset_parameter(bagging_fraction=[0.7] * 5 + [0.6] * 5)])\n\nprint('Finish 30 - 40 rounds with changing bagging_fraction...')\n\n\n# self-defined objective function\n# f(preds: array, train_data: Dataset) -> grad: array, hess: array\n# log likelihood loss\ndef loglikelood(preds, train_data):\n    labels = train_data.get_label()\n    preds = 1. / (1. + np.exp(-preds))\n    grad = preds - labels\n    hess = preds * (1. - preds)\n    return grad, hess\n\n\n# self-defined eval metric\n# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n# binary error\ndef binary_error(preds, train_data):\n    labels = train_data.get_label()\n    return 'error', np.mean(labels != (preds > 0.5)), False\n\n\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=10,\n                init_model=gbm,\n                fobj=loglikelood,\n                feval=binary_error,\n                valid_sets=lgb_eval)\n\nprint('Finish 40 - 50 rounds with self-defined objective function and eval metric...')\n\nprint('Start a new training job...')\n\n\n# callback\ndef reset_metrics():\n    def callback(env):\n        lgb_eval_new = lgb.Dataset(X_test, y_test, reference=lgb_train)\n        if env.iteration - env.begin_iteration == 5:\n            print('Add a new valid dataset at iteration 5...')\n            env.model.add_valid(lgb_eval_new, 'new valid')\n    callback.before_iteration = True\n    callback.order = 0\n    return callback\n\n\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=10,\n                valid_sets=lgb_train,\n                callbacks=[reset_metrics()])\n\nprint('Finish first 10 rounds with callback function...')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}